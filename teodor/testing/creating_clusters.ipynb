{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# Sample data list\n",
    "data_list = ['LLM Powered Autonomous Agents is a concept discussed by Lilian Weng.',\n",
    " 'The date of the article is June 23, 2023.',\n",
    " 'The estimated reading time for the article is 31 minutes.',\n",
    " 'Lilian Weng is the author of the article.',\n",
    " 'Building agents with LLM as its core controller is a cool concept.',\n",
    " 'Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer, and BabyAGI, serve as inspiring examples.',\n",
    " 'The potentiality of LLM extends beyond generating well-written copies, stories, essays, and programs.',\n",
    " 'LLM can be framed as a powerful general problem solver.',\n",
    " 'In a LLM-powered autonomous agent system, LLM functions as the agent’s brain.',\n",
    " 'Several key components complement LLM in the agent system.',\n",
    " 'Planning is one of the key components of the agent system.',\n",
    " 'Task decomposition allows the agent to break down large tasks into smaller, manageable subgoals.',\n",
    " 'Self-reflection enables the agent to learn from mistakes and refine future actions.',\n",
    " 'Memory is another key component of the agent system.',\n",
    " 'Short-term memory is utilized for in-context learning.',\n",
    " 'Long-term memory provides the agent with the capability to retain and recall information over extended periods.',\n",
    " 'Tool use is a distinguishing characteristic of human beings.',\n",
    " 'Equipping LLMs with external tools can significantly extend the model capabilities.',\n",
    " 'MRKL is a neuro-symbolic architecture for autonomous agents.',\n",
    " 'MRKL systems contain a collection of expert modules.',\n",
    " 'The general-purpose LLM works as a router to route inquiries to the best suitable expert module.',\n",
    " 'TALM and Toolformer fine-tune a language model to learn to use external tool APIs.',\n",
    " 'ChatGPT Plugins and OpenAI API function calling are examples of LLMs augmented with tool use capability.',\n",
    " 'HuggingGPT is a framework to use ChatGPT as the task planner.',\n",
    " 'ChemCrow is a domain-specific example where LLM is augmented with expert-designed tools for scientific tasks.',\n",
    " 'Generative Agents is an experiment where virtual characters controlled by LLM-powered agents interact in a sandbox environment.',\n",
    " 'AutoGPT is a proof-of-concept demo for setting up autonomous agents with LLM as the main controller.',\n",
    " 'The article discusses challenges such as finite context length and reliability of natural language interface.',\n",
    " 'The article includes citations and references for further reading.']\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data_list, columns=['sentences'])\n",
    "\n",
    "# Add a unique ID for each entry\n",
    "df['uuid'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "\n",
    "# Add the specified UUID to all entries\n",
    "df['text_id'] = \"78a7d0ea-0d7d-4b99-827b-83fab343a86e\"\n",
    "\n",
    "# Create SQLite engine\n",
    "engine = create_engine('sqlite:///test.db')\n",
    "\n",
    "# Upload DataFrame to SQLite\n",
    "df.to_sql('sentences', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='15755d07-16f7-44d2-899d-4769ae1762fe', metadata={'source': 'test', 'id': '15755d07-16f7-44d2-899d-4769ae1762fe'}, page_content='LLM Powered Autonomous Agents is a concept discussed by Lilian Weng.'),\n",
       " Document(id='1715d119-7e46-44df-b0d1-a1cd72d4b6de', metadata={'source': 'test', 'id': '1715d119-7e46-44df-b0d1-a1cd72d4b6de'}, page_content='The date of the article is June 23, 2023.'),\n",
       " Document(id='f12c2c1e-2ae1-403b-9ea5-51d6dcf0b769', metadata={'source': 'test', 'id': 'f12c2c1e-2ae1-403b-9ea5-51d6dcf0b769'}, page_content='The estimated reading time for the article is 31 minutes.'),\n",
       " Document(id='22610cc3-5138-44ad-9f84-af61dcf076f3', metadata={'source': 'test', 'id': '22610cc3-5138-44ad-9f84-af61dcf076f3'}, page_content='Lilian Weng is the author of the article.'),\n",
       " Document(id='97b55eba-12b5-4ad8-91b4-cf792ecd1936', metadata={'source': 'test', 'id': '97b55eba-12b5-4ad8-91b4-cf792ecd1936'}, page_content='Building agents with LLM as its core controller is a cool concept.'),\n",
       " Document(id='430dc150-a12a-4ecf-acb3-2fb9c51c3438', metadata={'source': 'test', 'id': '430dc150-a12a-4ecf-acb3-2fb9c51c3438'}, page_content='Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer, and BabyAGI, serve as inspiring examples.'),\n",
       " Document(id='78e038de-83ee-4296-a139-50908c24a441', metadata={'source': 'test', 'id': '78e038de-83ee-4296-a139-50908c24a441'}, page_content='The potentiality of LLM extends beyond generating well-written copies, stories, essays, and programs.'),\n",
       " Document(id='d2c0bacb-dd10-46ed-8640-22d3ddc19c2e', metadata={'source': 'test', 'id': 'd2c0bacb-dd10-46ed-8640-22d3ddc19c2e'}, page_content='LLM can be framed as a powerful general problem solver.'),\n",
       " Document(id='1469b80a-e709-4265-b301-6505877c7810', metadata={'source': 'test', 'id': '1469b80a-e709-4265-b301-6505877c7810'}, page_content='In a LLM-powered autonomous agent system, LLM functions as the agent’s brain.'),\n",
       " Document(id='88aae9f0-7f78-4a53-bf29-63a4aa3ca9a7', metadata={'source': 'test', 'id': '88aae9f0-7f78-4a53-bf29-63a4aa3ca9a7'}, page_content='Several key components complement LLM in the agent system.'),\n",
       " Document(id='a181329e-3d64-45a0-b358-a25ad3a3b4ac', metadata={'source': 'test', 'id': 'a181329e-3d64-45a0-b358-a25ad3a3b4ac'}, page_content='Planning is one of the key components of the agent system.'),\n",
       " Document(id='e4d9bf28-dde6-46ec-b81f-29cc21e979e2', metadata={'source': 'test', 'id': 'e4d9bf28-dde6-46ec-b81f-29cc21e979e2'}, page_content='Task decomposition allows the agent to break down large tasks into smaller, manageable subgoals.'),\n",
       " Document(id='504279e9-efd9-422f-be17-2e924c5ef168', metadata={'source': 'test', 'id': '504279e9-efd9-422f-be17-2e924c5ef168'}, page_content='Self-reflection enables the agent to learn from mistakes and refine future actions.'),\n",
       " Document(id='7ef29890-f5c9-4ff4-bda8-bd498e9e31a5', metadata={'source': 'test', 'id': '7ef29890-f5c9-4ff4-bda8-bd498e9e31a5'}, page_content='Memory is another key component of the agent system.'),\n",
       " Document(id='5e309082-8013-4ed4-8ab0-1db3709d1e40', metadata={'source': 'test', 'id': '5e309082-8013-4ed4-8ab0-1db3709d1e40'}, page_content='Short-term memory is utilized for in-context learning.'),\n",
       " Document(id='12333bfc-b737-47a8-93a8-a2bb6a800f75', metadata={'source': 'test', 'id': '12333bfc-b737-47a8-93a8-a2bb6a800f75'}, page_content='Long-term memory provides the agent with the capability to retain and recall information over extended periods.'),\n",
       " Document(id='5385fa8c-f1dd-47a4-bb91-07f45b731d52', metadata={'source': 'test', 'id': '5385fa8c-f1dd-47a4-bb91-07f45b731d52'}, page_content='Tool use is a distinguishing characteristic of human beings.'),\n",
       " Document(id='35316640-7f6c-4dde-9c73-5bb8b96163a6', metadata={'source': 'test', 'id': '35316640-7f6c-4dde-9c73-5bb8b96163a6'}, page_content='Equipping LLMs with external tools can significantly extend the model capabilities.'),\n",
       " Document(id='84fb992f-bbb0-445e-82c2-e60dfbb78f40', metadata={'source': 'test', 'id': '84fb992f-bbb0-445e-82c2-e60dfbb78f40'}, page_content='MRKL is a neuro-symbolic architecture for autonomous agents.'),\n",
       " Document(id='5d406d86-a4c5-44f5-bd9b-e6c961125e56', metadata={'source': 'test', 'id': '5d406d86-a4c5-44f5-bd9b-e6c961125e56'}, page_content='MRKL systems contain a collection of expert modules.'),\n",
       " Document(id='d3c4cdc6-cf37-44e1-86af-1e87d6acbdc8', metadata={'source': 'test', 'id': 'd3c4cdc6-cf37-44e1-86af-1e87d6acbdc8'}, page_content='The general-purpose LLM works as a router to route inquiries to the best suitable expert module.'),\n",
       " Document(id='cc16a35c-ba2d-46d8-b2b9-daa87f6bc031', metadata={'source': 'test', 'id': 'cc16a35c-ba2d-46d8-b2b9-daa87f6bc031'}, page_content='TALM and Toolformer fine-tune a language model to learn to use external tool APIs.'),\n",
       " Document(id='8df081f8-e1f1-464d-95a9-77b0a5a02453', metadata={'source': 'test', 'id': '8df081f8-e1f1-464d-95a9-77b0a5a02453'}, page_content='ChatGPT Plugins and OpenAI API function calling are examples of LLMs augmented with tool use capability.'),\n",
       " Document(id='2f859655-181c-4b61-80d1-106eb51b2de8', metadata={'source': 'test', 'id': '2f859655-181c-4b61-80d1-106eb51b2de8'}, page_content='HuggingGPT is a framework to use ChatGPT as the task planner.'),\n",
       " Document(id='324ee919-27e3-4698-bbda-ab22851ba1ff', metadata={'source': 'test', 'id': '324ee919-27e3-4698-bbda-ab22851ba1ff'}, page_content='ChemCrow is a domain-specific example where LLM is augmented with expert-designed tools for scientific tasks.'),\n",
       " Document(id='fd48d3b6-f14c-4585-a62b-6c390f5f3626', metadata={'source': 'test', 'id': 'fd48d3b6-f14c-4585-a62b-6c390f5f3626'}, page_content='Generative Agents is an experiment where virtual characters controlled by LLM-powered agents interact in a sandbox environment.'),\n",
       " Document(id='7358e65e-675e-4f7e-9648-d2701885462e', metadata={'source': 'test', 'id': '7358e65e-675e-4f7e-9648-d2701885462e'}, page_content='AutoGPT is a proof-of-concept demo for setting up autonomous agents with LLM as the main controller.'),\n",
       " Document(id='a3089730-b9cc-44d8-b57c-784dbf2c3b17', metadata={'source': 'test', 'id': 'a3089730-b9cc-44d8-b57c-784dbf2c3b17'}, page_content='The article discusses challenges such as finite context length and reliability of natural language interface.'),\n",
       " Document(id='b797f608-d266-4a07-b180-971f694595b6', metadata={'source': 'test', 'id': 'b797f608-d266-4a07-b180-971f694595b6'}, page_content='The article includes citations and references for further reading.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Create an SQLite database\n",
    "DATABASE_URL = \"sqlite:///./test.db\"\n",
    "\n",
    "# Create an engine\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Retrieve UUIDs from the 'page_content' table\n",
    "ids = []\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT uuid FROM sentences\"))\n",
    "    ids.extend([str(row[0]) for row in result])\n",
    "\n",
    "page_contents = {}\n",
    "with engine.connect() as connection:\n",
    "    for uuid in ids:\n",
    "        result = connection.execute(text(\"SELECT sentences FROM sentences WHERE uuid = :uuid\"), {'uuid': uuid})\n",
    "        for row in result:\n",
    "            page_contents[uuid] = row[0]\n",
    "\n",
    "# Separate the page contents into a list\n",
    "sentences = list(page_contents.values())\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "import uuid\n",
    "\n",
    "sentence_documents = []\n",
    "\n",
    "for text in sentences:\n",
    "    id = str(uuid.uuid4())\n",
    "    sentence_documents.append(Document(id=id , page_content=text, metadata={'source': 'test', \"id\": id}))\n",
    "\n",
    "sentence_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "ASTRA_DB_API_KEY = os.getenv('ASTRA_DB_API_KEY')\n",
    "ASTRA_DB_ENDPOINT = os.getenv('ASTRA_DB_ENDPOINT')\n",
    "ASTRA_DB_KEYSPACE = os.getenv('ASTRA_DB_KEYSPACE')\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "#text_embeddings = embeddings.embed_documents(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import SQLiteVec\n",
    "\n",
    "\n",
    "\n",
    "# create the open-source embedding function\n",
    "\n",
    "connection = SQLiteVec.create_connection(db_file=DATABASE_URL)\n",
    "\n",
    "db1 = SQLiteVec(\n",
    "    table=\"vectorstore\", \n",
    "    embedding=embeddings, \n",
    "    connection=connection\n",
    ")\n",
    "\n",
    "db1.add_documents(sentence_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import struct\n",
    "import sqlite3\n",
    "import sqlite_vec\n",
    "\n",
    "# Create an SQLite database\n",
    "DATABASE_URL = \"./vec.db\"\n",
    "\n",
    "db = sqlite3.connect(DATABASE_URL)\n",
    "db.enable_load_extension(True)\n",
    "sqlite_vec.load(db)\n",
    "db.enable_load_extension(False)\n",
    "\n",
    "\n",
    "# Example query to retrieve vectors\n",
    "query = \"SELECT text_embedding FROM vectorstore\"\n",
    "result = db.execute(query).fetchall()\n",
    "\n",
    "# Deserialize the vectors\n",
    "def deserialize_float32(blob):\n",
    "    return struct.unpack(f'{len(blob) // 4}f', blob)\n",
    "\n",
    "text_embeddings = [deserialize_float32(row[0]) for row in result]\n",
    "\n",
    "len(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "  - The date of the article is June 23, 2023.\n",
      "  - The estimated reading time for the article is 31 minutes.\n",
      "  - Planning is one of the key components of the agent system.\n",
      "  - Self-reflection enables the agent to learn from mistakes and refine future actions.\n",
      "  - Memory is another key component of the agent system.\n",
      "  - Short-term memory is utilized for in-context learning.\n",
      "  - Long-term memory provides the agent with the capability to retain and recall information over extended periods.\n",
      "\n",
      "Cluster 1:\n",
      "  - The potentiality of LLM extends beyond generating well-written copies, stories, essays, and programs.\n",
      "  - LLM can be framed as a powerful general problem solver.\n",
      "  - Several key components complement LLM in the agent system.\n",
      "  - Tool use is a distinguishing characteristic of human beings.\n",
      "  - Equipping LLMs with external tools can significantly extend the model capabilities.\n",
      "  - The general-purpose LLM works as a router to route inquiries to the best suitable expert module.\n",
      "  - TALM and Toolformer fine-tune a language model to learn to use external tool APIs.\n",
      "  - ChatGPT Plugins and OpenAI API function calling are examples of LLMs augmented with tool use capability.\n",
      "  - ChemCrow is a domain-specific example where LLM is augmented with expert-designed tools for scientific tasks.\n",
      "  - The article discusses challenges such as finite context length and reliability of natural language interface.\n",
      "  - The article includes citations and references for further reading.\n",
      "\n",
      "Cluster 2:\n",
      "  - MRKL is a neuro-symbolic architecture for autonomous agents.\n",
      "  - MRKL systems contain a collection of expert modules.\n",
      "\n",
      "Cluster 3:\n",
      "  - LLM Powered Autonomous Agents is a concept discussed by Lilian Weng.\n",
      "  - Lilian Weng is the author of the article.\n",
      "  - Building agents with LLM as its core controller is a cool concept.\n",
      "  - Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer, and BabyAGI, serve as inspiring examples.\n",
      "  - In a LLM-powered autonomous agent system, LLM functions as the agent’s brain.\n",
      "  - Task decomposition allows the agent to break down large tasks into smaller, manageable subgoals.\n",
      "  - HuggingGPT is a framework to use ChatGPT as the task planner.\n",
      "  - Generative Agents is an experiment where virtual characters controlled by LLM-powered agents interact in a sandbox environment.\n",
      "  - AutoGPT is a proof-of-concept demo for setting up autonomous agents with LLM as the main controller.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 4\n",
    "\n",
    "# Cluster the embeddings and assign a cluster to each proposition\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(text_embeddings)\n",
    "cluster_assignments = kmeans.labels_\n",
    "\n",
    "# Create a list of dict to store the embeddings, the text, and the cluster assignment\n",
    "props_clustered = [\n",
    "    {\"text\": prop, \"embeddings\": emb, \"cluster\": cluster}\n",
    "    for prop, emb, cluster in zip(sentences, text_embeddings, cluster_assignments)\n",
    "]\n",
    "\n",
    "# Display clusters and their propositions\n",
    "\n",
    "for cluster in range(num_clusters):\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    for prop in props_clustered:\n",
    "        if prop[\"cluster\"] == cluster:\n",
    "            print(f\"  - {prop['text']}\")\n",
    "    print() \n",
    "len(props_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0.0:\n",
      "  - LLM Powered Autonomous Agents is a concept discussed by Lilian Weng.\n",
      "  - Building agents with LLM as its core controller is a cool concept.\n",
      "  - Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer, and BabyAGI, serve as inspiring examples.\n",
      "  - In a LLM-powered autonomous agent system, LLM functions as the agent’s brain.\n",
      "  - Several key components complement LLM in the agent system.\n",
      "  - Generative Agents is an experiment where virtual characters controlled by LLM-powered agents interact in a sandbox environment.\n",
      "  - AutoGPT is a proof-of-concept demo for setting up autonomous agents with LLM as the main controller.\n",
      "Cluster 1.0:\n",
      "  - The date of the article is June 23, 2023.\n",
      "Cluster 2.0:\n",
      "  - The estimated reading time for the article is 31 minutes.\n",
      "Cluster 3.0:\n",
      "  - Lilian Weng is the author of the article.\n",
      "Cluster 4.0:\n",
      "  - The potentiality of LLM extends beyond generating well-written copies, stories, essays, and programs.\n",
      "  - LLM can be framed as a powerful general problem solver.\n",
      "  - The general-purpose LLM works as a router to route inquiries to the best suitable expert module.\n",
      "Cluster 5.0:\n",
      "  - Planning is one of the key components of the agent system.\n",
      "  - Memory is another key component of the agent system.\n",
      "  - Long-term memory provides the agent with the capability to retain and recall information over extended periods.\n",
      "Cluster 6.0:\n",
      "  - Task decomposition allows the agent to break down large tasks into smaller, manageable subgoals.\n",
      "Cluster 7.0:\n",
      "  - Self-reflection enables the agent to learn from mistakes and refine future actions.\n",
      "Cluster 8.0:\n",
      "  - Short-term memory is utilized for in-context learning.\n",
      "Cluster 9.0:\n",
      "  - Tool use is a distinguishing characteristic of human beings.\n",
      "Cluster 10.0:\n",
      "  - Equipping LLMs with external tools can significantly extend the model capabilities.\n",
      "Cluster 11.0:\n",
      "  - MRKL is a neuro-symbolic architecture for autonomous agents.\n",
      "  - MRKL systems contain a collection of expert modules.\n",
      "Cluster 12.0:\n",
      "  - TALM and Toolformer fine-tune a language model to learn to use external tool APIs.\n",
      "Cluster 13.0:\n",
      "  - ChatGPT Plugins and OpenAI API function calling are examples of LLMs augmented with tool use capability.\n",
      "Cluster 14.0:\n",
      "  - HuggingGPT is a framework to use ChatGPT as the task planner.\n",
      "Cluster 15.0:\n",
      "  - ChemCrow is a domain-specific example where LLM is augmented with expert-designed tools for scientific tasks.\n",
      "Cluster 16.0:\n",
      "  - The article discusses challenges such as finite context length and reliability of natural language interface.\n",
      "Cluster 17.0:\n",
      "  - The article includes citations and references for further reading.\n",
      "29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cluster_embeddings(embeddings, radius=0.01):\n",
    "    n = len(embeddings)\n",
    "    labels = -np.ones(n)  # Initialize all labels to -1 (unlabeled)\n",
    "    current_label = 0\n",
    "\n",
    "    def label_cluster(center_idx):\n",
    "        nonlocal current_label\n",
    "        to_label = [center_idx]\n",
    "        while to_label:\n",
    "            idx = to_label.pop()\n",
    "            if labels[idx] == -1:  # If not labeled\n",
    "                labels[idx] = current_label\n",
    "                similarities = cosine_similarity([embeddings[idx]], embeddings)[0]\n",
    "                neighbors = np.where(similarities > 1 - radius)[0]\n",
    "                to_label.extend(neighbors)\n",
    "        current_label += 1\n",
    "\n",
    "    for i in range(n):\n",
    "        if labels[i] == -1:  # If not labeled\n",
    "            label_cluster(i)\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Example usage\n",
    "radius = 0.14  # Adjust this value based on your needs\n",
    "cluster_assignments = cluster_embeddings(text_embeddings, radius)\n",
    "\n",
    "# Create a list of dict to store the embeddings, the text, and the cluster assignment\n",
    "props_clustered = [\n",
    "    {\"text\": prop, \"embeddings\": emb, \"cluster\": cluster}\n",
    "    for prop, emb, cluster in zip(sentences, text_embeddings, cluster_assignments)\n",
    "]\n",
    "\n",
    "# Display clusters and their propositions\n",
    "for cluster in set(cluster_assignments):\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    for prop in props_clustered:\n",
    "        if prop[\"cluster\"] == cluster:\n",
    "            print(f\"  - {prop['text']}\")\n",
    "print(len(props_clustered))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

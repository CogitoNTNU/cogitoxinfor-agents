{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "ASTRA_DB_API_KEY = os.getenv('ASTRA_DB_API_KEY')\n",
    "ASTRA_DB_ENDPOINT = os.getenv('ASTRA_DB_ENDPOINT')\n",
    "ASTRA_DB_KEYSPACE = os.getenv('ASTRA_DB_KEYSPACE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import TransformChain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import globals\n",
    "from langchain_core.runnables import chain\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "\n",
    "def load_image(inputs: dict) -> dict:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    image_path = inputs[\"image_path\"]\n",
    "  \n",
    "    def encode_image(image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    image_base64 = encode_image(image_path)\n",
    "    return {\"image\": image_base64}\n",
    "\n",
    "load_image_chain = TransformChain(\n",
    "    input_variables=[\"image_path\"],\n",
    "    output_variables=[\"image\"],\n",
    "    transform=load_image\n",
    ")\n",
    "\n",
    "\n",
    "class ImageInformation(BaseModel):\n",
    "    \"\"\"Information about an image.\"\"\"\n",
    "    image_description: str = Field(description=\"a short description of the image\")\n",
    "    people_count: int = Field(description=\"number of humans on the picture\")\n",
    "    main_objects: list[str] = Field(description=\"list of the main objects on the picture\")\n",
    "    humans: int = Field(description=\"number of humans on the picture\")\n",
    "    \n",
    "     \n",
    "# Set verbose\n",
    "globals.set_debug(True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@chain\n",
    "def image_agent(inputs: dict) -> str | list[str] | dict:\n",
    " \"\"\"Invoke model with image and prompt.\"\"\"\n",
    " model = ChatOpenAI(temperature=0.5, model=\"gpt-4o-mini\", max_tokens=1024)\n",
    " msg = model.invoke(\n",
    "             [HumanMessage(\n",
    "             content=[\n",
    "             {\"type\": \"text\", \"text\": inputs[\"prompt\"]},\n",
    "             {\"type\": \"text\", \"text\": parser.get_format_instructions()},\n",
    "             {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{inputs['image']}\"}},\n",
    "             ])]\n",
    "             )\n",
    " return msg.content\n",
    "\n",
    "\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=ImageInformation)\n",
    "\n",
    "def get_image_informations(image_path: str) -> dict:\n",
    "   vision_prompt = \"\"\"\n",
    "   Given the image, provide the following information:\n",
    "   - A count of how many people are in the image\n",
    "   - A list of the main objects present in the image\n",
    "   - A description of the image\n",
    "   \"\"\"\n",
    "   vision_chain = load_image_chain | image_agent | parser\n",
    "   return vision_chain.invoke({'image_path': f'{image_path}', \n",
    "                               'prompt': vision_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.5, model=\"gpt-4o-mini\", max_tokens=1024)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ImageInformation(BaseModel):\n",
    "    \"\"\"Information about an image.\"\"\"\n",
    "    image_description: str = Field(description=\"a short description of the image\")\n",
    "    people_count: int = Field(description=\"number of humans on the picture\")\n",
    "    main_objects: list[str] = Field(description=\"list of the main objects on the picture\")\n",
    "    humans: int = Field(description=\"number of humans on the picture\")\n",
    "\n",
    "\n",
    "\n",
    "structured_image_agent = llm.with_structured_output(ImageInformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"image_path\": \"path/to/your/image.jpg\",\n",
      "  \"prompt\": \"\\n   Given the image, provide the following information:\\n   - A count of how many people are in the image\\n   - A list of the main objects present in the image\\n   - A description of the image\\n   \"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:TransformChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"image_path\": \"path/to/your/image.jpg\",\n",
      "  \"prompt\": \"\\n   Given the image, provide the following information:\\n   - A count of how many people are in the image\\n   - A list of the main objects present in the image\\n   - A description of the image\\n   \"\n",
      "}\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:TransformChain] [3ms] Chain run errored with error:\n",
      "\u001b[0m\"FileNotFoundError(2, 'No such file or directory')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/teodorrk/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/langchain/chains/base.py\\\", line 160, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/home/teodorrk/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/langchain/chains/transform.py\\\", line 70, in _call\\n    return self.transform_cb(inputs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/tmp/ipykernel_943647/1177642114.py\\\", line 17, in load_image\\n    image_base64 = encode_image(image_path)\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/tmp/ipykernel_943647/1177642114.py\\\", line 15, in encode_image\\n    with open(image_path, \\\"rb\\\") as image_file:\\n         ^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/home/teodorrk/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\\\", line 325, in _modified_open\\n    return io_open(file, *args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\nFileNotFoundError: [Errno 2] No such file or directory: 'path/to/your/image.jpg'\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RunnableSequence] [6ms] Chain run errored with error:\n",
      "\u001b[0m\"FileNotFoundError(2, 'No such file or directory')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/teodorrk/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/langchain_core/runnables/base.py\\\", line 3027, in invoke\\n    input = context.run(step.invoke, input, config, **kwargs)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/home/teodorrk/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/langchain/chains/base.py\\\", line 170, in invoke\\n    raise e\\n\\n\\n  File \\\"/home/teodorrk/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/langchain/chains/base.py\\\", line 160, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/home/teodorrk/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/langchain/chains/transform.py\\\", line 70, in _call\\n    return self.transform_cb(inputs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/tmp/ipykernel_943647/1177642114.py\\\", line 17, in load_image\\n    image_base64 = encode_image(image_path)\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/tmp/ipykernel_943647/1177642114.py\\\", line 15, in encode_image\\n    with open(image_path, \\\"rb\\\") as image_file:\\n         ^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/home/teodorrk/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\\\", line 325, in _modified_open\\n    return io_open(file, *args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\nFileNotFoundError: [Errno 2] No such file or directory: 'path/to/your/image.jpg'\"\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/your/image.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = \u001b[43mget_image_informations\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath/to/your/image.jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mget_image_informations\u001b[39m\u001b[34m(image_path)\u001b[39m\n\u001b[32m     60\u001b[39m vision_prompt = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[33mGiven the image, provide the following information:\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[33m- A count of how many people are in the image\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[33m- A list of the main objects present in the image\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[33m- A description of the image\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     66\u001b[39m vision_chain = load_image_chain | image_agent | parser\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvision_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimage_path\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimage_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m                            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvision_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3027\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3025\u001b[39m context.run(_set_config_context, config)\n\u001b[32m   3026\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3027\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3029\u001b[39m     \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/langchain/chains/base.py:170\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    169\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    171\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/langchain/chains/base.py:160\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    159\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    163\u001b[39m     )\n\u001b[32m    165\u001b[39m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    166\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    167\u001b[39m     )\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/langchain/chains/transform.py:70\u001b[39m, in \u001b[36mTransformChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     67\u001b[39m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[32m     68\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     69\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform_cb\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mload_image\u001b[39m\u001b[34m(inputs)\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(image_path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m image_file:\n\u001b[32m     16\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m base64.b64encode(image_file.read()).decode(\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m image_base64 = \u001b[43mencode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m: image_base64}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mload_image.<locals>.encode_image\u001b[39m\u001b[34m(image_path)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_image\u001b[39m(image_path):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image_file:\n\u001b[32m     16\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m base64.b64encode(image_file.read()).decode(\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cogitoxinfor-agents/.myvenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'path/to/your/image.jpg'"
     ]
    }
   ],
   "source": [
    "result = get_image_informations(\"path/to/your/image.jpg\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

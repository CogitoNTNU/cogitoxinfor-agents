{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# Sample data list\n",
    "data_list = ['LLM Powered Autonomous Agents is a concept discussed by Lilian Weng.',\n",
    " 'The date of the article is June 23, 2023.',\n",
    " 'The estimated reading time for the article is 31 minutes.',\n",
    " 'Lilian Weng is the author of the article.',\n",
    " 'Building agents with LLM as its core controller is a cool concept.',\n",
    " 'Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer, and BabyAGI, serve as inspiring examples.',\n",
    " 'The potentiality of LLM extends beyond generating well-written copies, stories, essays, and programs.',\n",
    " 'LLM can be framed as a powerful general problem solver.',\n",
    " 'In a LLM-powered autonomous agent system, LLM functions as the agent’s brain.',\n",
    " 'Several key components complement LLM in the agent system.',\n",
    " 'Planning is one of the key components of the agent system.',\n",
    " 'Task decomposition allows the agent to break down large tasks into smaller, manageable subgoals.',\n",
    " 'Self-reflection enables the agent to learn from mistakes and refine future actions.',\n",
    " 'Memory is another key component of the agent system.',\n",
    " 'Short-term memory is utilized for in-context learning.',\n",
    " 'Long-term memory provides the agent with the capability to retain and recall information over extended periods.',\n",
    " 'Tool use is a distinguishing characteristic of human beings.',\n",
    " 'Equipping LLMs with external tools can significantly extend the model capabilities.',\n",
    " 'MRKL is a neuro-symbolic architecture for autonomous agents.',\n",
    " 'MRKL systems contain a collection of expert modules.',\n",
    " 'The general-purpose LLM works as a router to route inquiries to the best suitable expert module.',\n",
    " 'TALM and Toolformer fine-tune a language model to learn to use external tool APIs.',\n",
    " 'ChatGPT Plugins and OpenAI API function calling are examples of LLMs augmented with tool use capability.',\n",
    " 'HuggingGPT is a framework to use ChatGPT as the task planner.',\n",
    " 'ChemCrow is a domain-specific example where LLM is augmented with expert-designed tools for scientific tasks.',\n",
    " 'Generative Agents is an experiment where virtual characters controlled by LLM-powered agents interact in a sandbox environment.',\n",
    " 'AutoGPT is a proof-of-concept demo for setting up autonomous agents with LLM as the main controller.',\n",
    " 'The article discusses challenges such as finite context length and reliability of natural language interface.',\n",
    " 'The article includes citations and references for further reading.']\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data_list, columns=['sentences'])\n",
    "\n",
    "# Add a unique ID for each entry\n",
    "df['uuid'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "\n",
    "# Add the specified UUID to all entries\n",
    "df['text_id'] = \"78a7d0ea-0d7d-4b99-827b-83fab343a86e\"\n",
    "\n",
    "# Create SQLite engine\n",
    "engine = create_engine('sqlite:///test.db')\n",
    "\n",
    "# Upload DataFrame to SQLite\n",
    "df.to_sql('sentences', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Create an SQLite database\n",
    "DATABASE_URL = \"sqlite:///./test.db\"\n",
    "\n",
    "# Create an engine\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Retrieve UUIDs from the 'page_content' table\n",
    "ids = []\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT uuid FROM sentences\"))\n",
    "    ids.extend([str(row[0]) for row in result])\n",
    "\n",
    "page_contents = {}\n",
    "with engine.connect() as connection:\n",
    "    for uuid in ids:\n",
    "        result = connection.execute(text(\"SELECT sentences FROM sentences WHERE uuid = :uuid\"), {'uuid': uuid})\n",
    "        for row in result:\n",
    "            page_contents[uuid] = row[0]\n",
    "\n",
    "# Separate the page contents into a list\n",
    "sentences = list(page_contents.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LLM Powered Autonomous Agents is a concept discussed by Lilian Weng.',\n",
       " 'The date of the article is June 23, 2023.',\n",
       " 'The estimated reading time for the article is 31 minutes.',\n",
       " 'Lilian Weng is the author of the article.',\n",
       " 'Building agents with LLM as its core controller is a cool concept.',\n",
       " 'Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer, and BabyAGI, serve as inspiring examples.',\n",
       " 'The potentiality of LLM extends beyond generating well-written copies, stories, essays, and programs.',\n",
       " 'LLM can be framed as a powerful general problem solver.',\n",
       " 'In a LLM-powered autonomous agent system, LLM functions as the agent’s brain.',\n",
       " 'Several key components complement LLM in the agent system.',\n",
       " 'Planning is one of the key components of the agent system.',\n",
       " 'Task decomposition allows the agent to break down large tasks into smaller, manageable subgoals.',\n",
       " 'Self-reflection enables the agent to learn from mistakes and refine future actions.',\n",
       " 'Memory is another key component of the agent system.',\n",
       " 'Short-term memory is utilized for in-context learning.',\n",
       " 'Long-term memory provides the agent with the capability to retain and recall information over extended periods.',\n",
       " 'Tool use is a distinguishing characteristic of human beings.',\n",
       " 'Equipping LLMs with external tools can significantly extend the model capabilities.',\n",
       " 'MRKL is a neuro-symbolic architecture for autonomous agents.',\n",
       " 'MRKL systems contain a collection of expert modules.',\n",
       " 'The general-purpose LLM works as a router to route inquiries to the best suitable expert module.',\n",
       " 'TALM and Toolformer fine-tune a language model to learn to use external tool APIs.',\n",
       " 'ChatGPT Plugins and OpenAI API function calling are examples of LLMs augmented with tool use capability.',\n",
       " 'HuggingGPT is a framework to use ChatGPT as the task planner.',\n",
       " 'ChemCrow is a domain-specific example where LLM is augmented with expert-designed tools for scientific tasks.',\n",
       " 'Generative Agents is an experiment where virtual characters controlled by LLM-powered agents interact in a sandbox environment.',\n",
       " 'AutoGPT is a proof-of-concept demo for setting up autonomous agents with LLM as the main controller.',\n",
       " 'The article discusses challenges such as finite context length and reliability of natural language interface.',\n",
       " 'The article includes citations and references for further reading.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "ASTRA_DB_API_KEY = os.getenv('ASTRA_DB_API_KEY')\n",
    "ASTRA_DB_ENDPOINT = os.getenv('ASTRA_DB_ENDPOINT')\n",
    "ASTRA_DB_KEYSPACE = os.getenv('ASTRA_DB_KEYSPACE')\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "text_embeddings = embeddings.embed_documents(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import SQLiteVec\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create SQLite engine and connection\n",
    "engine = create_engine('sqlite:///vec.db')\n",
    "connection = engine.connect()\n",
    "\n",
    "db = SQLiteVec.from_texts(\n",
    "    texts=sentences,\n",
    "    embedding=embeddings,\n",
    "    connection=connection,\n",
    "    table_name='vector_store'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='The article includes citations and references for further reading.'),\n",
       " Document(metadata={}, page_content='The article discusses challenges such as finite context length and reliability of natural language interface.'),\n",
       " Document(metadata={}, page_content='Lilian Weng is the author of the article.'),\n",
       " Document(metadata={}, page_content='The date of the article is June 23, 2023.'),\n",
       " Document(metadata={}, page_content='The estimated reading time for the article is 31 minutes.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is article about?\"\n",
    "data = db.similarity_search(query, k=5)\n",
    "\n",
    "# print results\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='The article includes citations and references for further reading.'),\n",
       " Document(metadata={}, page_content='The article discusses challenges such as finite context length and reliability of natural language interface.'),\n",
       " Document(metadata={}, page_content='Lilian Weng is the author of the article.'),\n",
       " Document(metadata={}, page_content='The date of the article is June 23, 2023.')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "  - The date of the article is June 23, 2023.\n",
      "  - The estimated reading time for the article is 31 minutes.\n",
      "  - Lilian Weng is the author of the article.\n",
      "  - The potentiality of LLM extends beyond generating well-written copies, stories, essays, and programs.\n",
      "  - Planning is one of the key components of the agent system.\n",
      "  - Task decomposition allows the agent to break down large tasks into smaller, manageable subgoals.\n",
      "  - Self-reflection enables the agent to learn from mistakes and refine future actions.\n",
      "  - Memory is another key component of the agent system.\n",
      "  - Short-term memory is utilized for in-context learning.\n",
      "  - Long-term memory provides the agent with the capability to retain and recall information over extended periods.\n",
      "  - Tool use is a distinguishing characteristic of human beings.\n",
      "  - The article discusses challenges such as finite context length and reliability of natural language interface.\n",
      "  - The article includes citations and references for further reading.\n",
      "\n",
      "Cluster 1:\n",
      "  - LLM Powered Autonomous Agents is a concept discussed by Lilian Weng.\n",
      "  - Building agents with LLM as its core controller is a cool concept.\n",
      "  - Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer, and BabyAGI, serve as inspiring examples.\n",
      "  - LLM can be framed as a powerful general problem solver.\n",
      "  - In a LLM-powered autonomous agent system, LLM functions as the agent’s brain.\n",
      "  - Several key components complement LLM in the agent system.\n",
      "  - Equipping LLMs with external tools can significantly extend the model capabilities.\n",
      "  - MRKL is a neuro-symbolic architecture for autonomous agents.\n",
      "  - MRKL systems contain a collection of expert modules.\n",
      "  - The general-purpose LLM works as a router to route inquiries to the best suitable expert module.\n",
      "  - TALM and Toolformer fine-tune a language model to learn to use external tool APIs.\n",
      "  - ChatGPT Plugins and OpenAI API function calling are examples of LLMs augmented with tool use capability.\n",
      "  - HuggingGPT is a framework to use ChatGPT as the task planner.\n",
      "  - ChemCrow is a domain-specific example where LLM is augmented with expert-designed tools for scientific tasks.\n",
      "  - Generative Agents is an experiment where virtual characters controlled by LLM-powered agents interact in a sandbox environment.\n",
      "  - AutoGPT is a proof-of-concept demo for setting up autonomous agents with LLM as the main controller.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Function to find the optimal number of clusters using silhouette score\n",
    "def find_optimal_clusters(embeddings, max_k):\n",
    "    iters = range(2, max_k+1)\n",
    "    s_scores = []\n",
    "    \n",
    "    for k in iters:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0).fit(embeddings)\n",
    "        s_scores.append(silhouette_score(embeddings, kmeans.labels_))\n",
    "    \n",
    "    optimal_k = iters[s_scores.index(max(s_scores))]\n",
    "    return optimal_k\n",
    "\n",
    "# Example usage\n",
    "max_k = 10  # You can adjust this value based on your needs\n",
    "optimal_clusters = find_optimal_clusters(text_embeddings, max_k)\n",
    "\n",
    "# Cluster the embeddings with the optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=0).fit(text_embeddings)\n",
    "cluster_assignments = kmeans.labels_\n",
    "\n",
    "# Create a list of dict to store the embeddings, the text, and the cluster assignment\n",
    "props_clustered = [\n",
    "    {\"text\": prop, \"embeddings\": emb, \"cluster\": cluster}\n",
    "    for prop, emb, cluster in zip(sentences, text_embeddings, cluster_assignments)\n",
    "]\n",
    "\n",
    "# Display clusters and their propositions\n",
    "for cluster in range(optimal_clusters):\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    for prop in props_clustered:\n",
    "        if prop[\"cluster\"] == cluster:\n",
    "            print(f\"  - {prop['text']}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
